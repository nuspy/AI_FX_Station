# Configuration for MagicForex - consolidated defaults
# Override with environment-specific YAML or env vars.
# NOTE: keep sampler.steps <= 20 for production/service constraints.

app:
  name: "magicforex"
  debug: false
  seed: 42
  alembic_upgrade_on_start: true
  artifacts_dir: "./artifacts"
  temp_dir: "./tmp"
  # At startup the app will run alembic upgrade head and then backfill per-configured symbols/timeframes
  startup:
    run_backfill: true
    parallel_backfill_workers: 4

db:
  # SQLite for MVP; file path relative to project root
  dialect: "sqlite"
  database_url: "sqlite:///./data/forex_diffusion.db"
  pool_size: 5
  # DB writer queue settings
  writer:
    max_queue: 1000
    commit_batch: 500

alembic:
  script_location: "migrations"
  env: "production"

providers:
  default: "tiingo"
  secondary: "ctrader"  # Failover provider

  tiingo:
    enabled: true
    key: "${TIINGO_API_KEY:d867b4314010495a5fa40593610eb3deae5e2dcd}"
    base_url: "https://api.tiingo.com"
    ws_uri: "wss://api.tiingo.com/fx"
    # Tiingo rate limits and other options can be configured here if needed

  ctrader:
    enabled: false
    environment: "demo"  # "demo" or "live"
    client_id: "${CTRADER_CLIENT_ID:-}"
    client_secret: "${CTRADER_CLIENT_SECRET:-}"
    # OAuth tokens stored in keyring (managed by CredentialsManager)

  alpha_vantage:
    enabled: true
    key: "${ALPHAVANTAGE_KEY:-YOUR_ALPHA_VANTAGE_KEY}"
    base_url: "https://www.alphavantage.co/query"
    rate_limit_per_minute: 5
    retry:
      attempts: 8
      backoff_base_seconds: 1.0
      max_backoff_seconds: 60.0

  dukascopy:
    enabled: false
    key: "${DUKASCOPY_KEY:-}"
    rest:
      base_url: "https://www.dukascopy.com"
      endpoints:
        currentPrices: "/rest/currentPrices"
        historicalPrices: "/rest/historicalPrices"
    retry:
      attempts: 6
      backoff_base_seconds: 1.0
      max_backoff_seconds: 60.0

data:
  symbols:
    - "EUR/USD"
    - "USD/JPY"
    - "GBP/USD"
  # Historical backfill preferences
  backfill:
    history_years: 20
    intraday_recent_days: 90
    intraday_base_tf: "1m"
    # if provider doesn't return minute history for full 20y, use daily for long-run and intraday recent segment
    prefer_daily_for_longrun: true
    # Days per REST API call when fetching historical candles (default: 7 = one week)
    rest_batch_days: 7
  storage:
    resampled_flag_field: "resampled"
    # unique key enforced: (symbol, timeframe, ts_utc)
    unique_index: true

timeframes:
  native:
    - "1m"
    - "5m"
    - "15m"
    - "30m"
    - "60m"
    - "1d"
  # If target timeframe is not native, resample causally from lower granularity
  resample_map:
    "2m": "1m"
    "3m": "1m"
    "4m": "1m"
    "2h": "60m"
    "4h": "60m"

horizons:
  # Horizons expressed as human label -> minutes
  list:
    - label: "1m"
      minutes: 1
    - label: "5m"
      minutes: 5
    - label: "15m"
      minutes: 15
    - label: "30m"
      minutes: 30
    - label: "60m"
      minutes: 60
    # multi-hour up to 24h
    - label: "2h"
      minutes: 120
    - label: "4h"
      minutes: 240
    - label: "8h"
      minutes: 480
    - label: "12h"
      minutes: 720
    - label: "24h"
      minutes: 1440
    # multi-day
    - label: "1d"
      minutes: 1440
    - label: "2d"
      minutes: 2880
    - label: "3d"
      minutes: 4320
    - label: "5d"
      minutes: 7200
  quantiles:
    - 0.05
    - 0.5
    - 0.95

model:
  artifacts_dir: "./artifacts/models"
  max_saved: 10
  versioning: true
  metadata:
    include_scaler: true
    patch_len: 64
    z_dim: 128

vae:
  patch_len: 64
  stride: 1
  channels:
    - "open"
    - "high"
    - "low"
    - "close"
    - "volume"
    - "hour_sin"
    - "hour_cos"
  z_dim: 128
  encoder:
    hidden_channels: 256
    n_layers: 6
  decoder:
    hidden_channels: 256
    n_layers: 6
  loss:
    recon_weight: 1.0
    kl_weight_max: 1.0
    kl_anneal:
      type: "logistic"  # logistic | linear
      warmup_steps: 10000
      k: 0.002

diffusion:
  # Timesteps for forward process (we use cosine schedule)
  T: 1000
  schedule:
    type: "cosine"
    s: 0.008
  parametrization: "v_prediction"  # v-prediction (Imagen) recommended
  conditioning:
    multi_scale_pool: [1, 2, 5, 15, 60]
    horizon_embedding_dim: 64
    symbol_embedding_dim: 32
  training:
    lambda_v: 1.0
    lambda_crps: 1.0
    lambda_kl: 0.01

sampler:
  default: "ddim"
  ddim:
    steps: 20
    eta: 0.0
  dpmpp:
    steps: 20
    order: 2
  # safety: enforce <= 20 steps in code at runtime
  max_steps: 20

training:
  device: "auto"
  batch_size: 64
  num_workers: 8
  max_epochs: 200
  learning_rate: 2e-4
  weight_decay: 1e-6
  grad_clip_val: 1.0
  early_stopping:
    monitor: "val/crps_agg"
    patience: 12
    mode: "min"
  seed_everything: 42

inference:
  n_samples: 200
  batch_decode: 32
  apply_conformal_by_default: true
  crps_bootstrap_samples: 1000

calibration:
  method: "weighted_icp"  # weighted_icp | standard_icp | mondrian
  alpha: 0.10
  half_life_days: 30.0
  weight_lambda: 0.0231  # derived from half-life
  mondrian:
    enabled: true
    buckets: ["session", "volatility_bucket"]
  # fallback to symmetric or asymmetric envelopes
  symmetric: false
  base_delta_scale: 1.0

features:
  standardization:
    mode: "rolling"  # rolling | static
    window_bars: 1000
  indicators:
    atr:
      n: 14
      method: "wilder"  # wilder | sma
    bollinger:
      n: 20
      k: 2.0
    macd:
      fast: 12
      slow: 26
      signal: 9
    rsi:
      n: 14
    hurst:
      window: 256
  warmup_bars: 512

# Persist features precomputed during backfill/realtime ingestion (optional; enable for faster training)
persist_features: true
persist_features_config:
  bulk_batch_size: 500
  retention_days: 365
  compaction_interval_hours: 24  # interval to run feature compaction (hours)

qa:
  outlier_zscore_threshold: 8.0
  gap_flag_multiplier: 1.1  # if delta > multiplier * expected_delta => flag
  report_dir: "./artifacts/reports"
  log_qa: true

backtest:
  walk_forward:
    n_splits: 5
    train_window_days: 730
    val_window_days: 90
    test_window_days: 90
  baseline:
    rw_sigma_window: 100
    spread_pips: 0.5
    slippage_pips: 0.2

gui:
  provider_default: "alpha_vantage"
  update_interval_ms: 250
  batch_update_size: 500
  non_blocking_workers: 6
  show_envelopes: true
  enable_realtime_feed: true
  plots:
    decimate_threshold: 10000
    crosshair_tooltip: true
  menus:
    enable_train: true
    enable_backtest: true
    enable_calibrate: true

logging:
  level: "DEBUG"
  file:
    enabled: true
    dir: "./logs"
    rotation: "10 MB"
    retention: "14 days"
  console:
    enabled: true
    rich: false

metrics:
  # CRPS baseline comparisons
  crps_rel_threshold: 0.01

debug:
  # developer switches
  simulate_provider_errors: false
  force_small_dataset: false

# =============================================================================
# ADVANCED PATTERN DETECTION & CACHING CONFIGURATION
# =============================================================================

# Cache e Performance
cache:
  redis:
    enabled: true
    path: "data/redis.db"  # Redis-lite embedded database
    max_memory_percent: 70  # % di RAM disponibile per cache (64GB * 70% = ~45GB)
    memory_policy: "allkeys-lru"  # LRU eviction policy
    key_ttl: 3600  # TTL default per chiavi cache (secondi)

  pattern_cache:
    max_entries: 100000  # Numero massimo pattern in cache
    ttl_minutes: 30  # TTL per pattern cached

  lru_cache:
    detection_cache_size: 50000  # Cache size per detection results
    parameter_cache_size: 10000  # Cache size per parameter combinations

# Resource Management
resources:
  pattern_detection:
    max_cpu_percent: 30  # Massimo 30% CPU per pattern detection
    max_workers: 8  # Numero worker threads/processes
    worker_type: "async"  # "async", "thread", "process"

  memory:
    max_usage_percent: 80  # Massimo utilizzo memoria
    gc_threshold: 85  # Soglia per garbage collection forzato

# Pattern Detection & Analysis
patterns:
  # Pattern Strength Calculation (senza volume)
  strength:
    weights:
      confidence: 0.35      # Confidence del detector
      volatility: 0.25      # Volatilità durante formazione
      historical_success: 0.25  # Success rate storico del pattern
      price_action: 0.15    # Qualità price action (range, momentum)

    # Scaling factors
    min_confidence: 0.3     # Confidence minima per considerare pattern
    volatility_window: 20   # Finestra per calcolo volatilità

  # Progressive Pattern Formation
  progressive:
    enabled: true
    confidence_threshold: 60  # % confidence per mostrare pattern in formazione
    update_frequency: "1min"  # Update ogni candela di 1 minuto
    visual:
      line_style: "dashed"   # Stile linee per pattern in formazione
      alpha: 0.6            # Trasparenza per pattern in formazione

  # Multi-timeframe Detection
  multi_timeframe:
    enabled: true
    combinations:
      # Combinazioni ottimali per performance
      - name: "scalping"
        timeframes: ["1m", "5m", "15m"]
        weights: [0.2, 0.3, 0.5]
      - name: "intraday"
        timeframes: ["15m", "1h", "4h"]
        weights: [0.2, 0.4, 0.4]
      - name: "swing"
        timeframes: ["1h", "4h", "1d"]
        weights: [0.3, 0.4, 0.3]

    # Composite Patterns
    composite:
      enabled: true
      types:
        - "head_shoulders_in_triangle"
        - "flag_in_wedge"
        - "double_top_with_divergence"
        - "elliott_wave_with_harmonics"

# Regime Detection (Machine Learning)
regime_detection:
  enabled: true
  method: "unsupervised_clustering"  # Unsupervised clustering

  # Gruppi logici di indicatori
  indicator_groups:
    trend_momentum:
      title: "Trend & Momentum Regime"
      indicators:
        - "sma_20_50_cross"      # Trend direction
        - "rsi_14"               # Momentum
        - "macd_signal"          # Momentum convergence
        - "adx_14"               # Trend strength
      weight: 0.3

    volatility_regime:
      title: "Volatility Regime"
      indicators:
        - "atr_14"               # Average True Range
        - "bollinger_bandwidth"   # Bollinger band width
        - "price_range_ratio"     # High-Low / Close ratio
        - "garch_volatility"      # GARCH volatility estimate
      weight: 0.25

    market_structure:
      title: "Market Structure Regime"
      indicators:
        - "support_resistance_strength"  # S/R level quality
        - "fractal_dimension"            # Market efficiency
        - "hurst_exponent"               # Trend persistence
        - "market_efficiency_ratio"      # Efficiency measure
      weight: 0.25

    sentiment_flow:
      title: "Market Sentiment Regime"
      indicators:
        - "price_momentum_divergence"    # Price vs momentum
        - "breakout_failure_rate"        # False breakout frequency
        - "gap_analysis"                 # Gap frequency/size
        - "reversal_pattern_frequency"   # Reversal vs continuation
      weight: 0.2

  # Clustering parameters
  clustering:
    n_clusters: 5          # Numero regimi da identificare
    algorithm: "kmeans"    # "kmeans", "dbscan", "gaussian_mixture"
    lookback_periods: 100  # Periodi storici per training
    update_frequency: "daily"  # Frequenza aggiornamento regimi

  # Per timeframe
  timeframes: ["1m", "5m", "15m", "1h", "4h", "1d"]

# Database & Parameters
database:
  # Parameter Selection Strategy
  parameters:
    selection_strategy: "historical_performance"  # Come scegliere parametri ottimali
    fallback_strategy: "skip_pattern"             # Cosa fare se parametri mancanti

    # Priorità selezione parametri
    priority_order:
      - "asset_timeframe_regime"    # Specifico per asset/timeframe/regime
      - "asset_timeframe"           # Specifico per asset/timeframe
      - "timeframe_regime"          # Specifico per timeframe/regime
      - "asset_regime"              # Specifico per asset/regime
      - "timeframe"                 # Solo timeframe
      - "default"                   # Parametri default

  # Optimization History
  optimization:
    min_trials: 100        # Minimo trial per considerare parametri validi
    min_success_rate: 0.4  # Success rate minimo per utilizzare parametri
    performance_window: 90 # Giorni di storia per valutare performance

# Advanced UI Configuration
advanced_ui:
  # Pattern strength display
  pattern_strength:
    display_type: "stars"  # "stars", "percentage", "numeric"
    max_stars: 5
    show_in_badge: true
    show_in_tooltip: true

  # Cache control GUI
  cache_control:
    show_usage_bar: true
    show_hit_rate: true
    allow_manual_clear: true

  # Progressive formation
  progressive_patterns:
    show_by_default: true
    confidence_display: true
    formation_percentage: true

  # Log tabs per GUI
  log_tabs:
    - name: "General"
      level: "INFO"
      sources: ["app", "ui", "data"]
    - name: "Patterns"
      level: "DEBUG"
      sources: ["patterns", "detection", "formation"]
    - name: "Optimization"
      level: "INFO"
      sources: ["optimization", "genetic", "trials"]
    - name: "Parameters"
      level: "WARNING"
      sources: ["parameters", "missing", "fallback"]
    - name: "Performance"
      level: "INFO"
      sources: ["performance", "resources", "cache"]

# Advanced Timeframe Configuration
advanced_timeframes:
  # Timeframe-specific settings
  settings:
    "1m":
      detection_sensitivity: "high"
      min_pattern_duration: 5      # minuti
      max_lookback: 100           # candele
    "5m":
      detection_sensitivity: "medium-high"
      min_pattern_duration: 15
      max_lookback: 200
    "15m":
      detection_sensitivity: "medium"
      min_pattern_duration: 45
      max_lookback: 300
    "1h":
      detection_sensitivity: "medium"
      min_pattern_duration: 180   # 3 ore
      max_lookback: 500
    "4h":
      detection_sensitivity: "medium-low"
      min_pattern_duration: 720   # 12 ore
      max_lookback: 1000
    "1d":
      detection_sensitivity: "low"
      min_pattern_duration: 2880  # 2 giorni
      max_lookback: 2000

# =============================================================================
# PROVIDER REFRESH RATES & DATA SOURCES
# =============================================================================

refresh_rates:
  # REST API polling intervals (seconds)
  rest:
    news_feed: 300           # 5 minutes
    economic_calendar: 21600 # 6 hours
    sentiment: 30            # 30 seconds
    dom_snapshot: 1          # 1 second (for REST DOM if available)

  # WebSocket settings
  websocket:
    reconnect_backoff: [1, 2, 4, 8, 16]  # Exponential backoff (max 16 sec)
    heartbeat_interval: 30     # Heartbeat every 30 seconds
    message_queue_size: 10000  # Max queued messages
    timeout: 120               # Connection timeout (seconds)

  # Database commit settings
  database:
    commit_interval: 60        # Commit every 60 seconds
    commit_batch_size: 1000    # Or every 1000 records
    vacuum_interval_days: 7    # Vacuum database every 7 days
    archive_after_days: 365    # Archive old data after 1 year

# Data source priority configuration
data_sources:
  # Which provider to use for which data type
  quotes:
    primary: "ctrader"
    fallback: "tiingo"
  historical_bars:
    primary: "tiingo"
    fallback: "ctrader"
  ticks:
    primary: "ctrader"
    fallback: "tiingo"
  dom:
    primary: "ctrader"
    fallback: null  # No fallback for DOM
  sentiment:
    primary: "ctrader"
    fallback: null
  news:
    primary: "ctrader"
    fallback: null
  calendar:
    primary: "ctrader"
    fallback: null
